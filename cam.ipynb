{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "2d7782b1",
         "metadata": {},
         "outputs": [],
         "source": [
            "%matplotlib inline\n",
            "import matplotlib.pyplot as plt\n",
            "import torch\n",
            "from torch.utils.data import Dataset\n",
            "import torch.nn.functional as F\n",
            "import torchvision.transforms as transforms\n",
            "from pycocotools.coco import COCO\n",
            "from PIL import Image\n",
            "import pylab\n",
            "pylab.rcParams['figure.figsize'] = (8.0, 10.0)\n",
            "from torch.utils.data import DataLoader\n",
            "import random\n",
            "from tqdm import tqdm\n",
            "\n",
            "from cam_net import AlexNet_GAP, GoogLeNet_GAP\n",
            "from cam_utils import label_data,overlay_cam_with_centroid, ResizeAndPad, ImageListDataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "963488ac",
         "metadata": {},
         "outputs": [],
         "source": [
            "data_dir = 'data'\n",
            "train_coco=COCO(f'{data_dir}/annotations/instances_train2017.json')\n",
            "val_coco=COCO(f'{data_dir}/annotations/instances_val2017.json')\n",
            "train_data = label_data(train_coco)\n",
            "val_data = label_data(val_coco)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "0efc360c",
         "metadata": {},
         "outputs": [],
         "source": [
            "# # Cross Validation\n",
            "# random.shuffle(all_data)\n",
            "# split = int(0.8 * len(all_data))\n",
            "# train_data, val_data = all_data[:split], all_data[split:]\n",
            "\n",
            "# Transform\n",
            "transform = transforms.Compose([\n",
            "    ResizeAndPad(target_size=224),\n",
            "    transforms.RandomHorizontalFlip,\n",
            "    transforms.ColorJitter(),\n",
            "    transforms.ToTensor(),\n",
            "    transforms.RandomHorizontalFlip(),\n",
            "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
            "                                 std=[0.229, 0.224, 0.225]),\n",
            "])\n",
            "\n",
            "# Datasets\n",
            "train_dir = f'{data_dir}/images/train'\n",
            "val_dir = f'{data_dir}/images/val'\n",
            "train_dataset = ImageListDataset(train_data, train_dir, transform)\n",
            "val_dataset = ImageListDataset(val_data, val_dir, transform)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "5bc8e588",
         "metadata": {},
         "outputs": [],
         "source": [
            "# DataLoaders\n",
            "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
            "val_loader = DataLoader(val_dataset, batch_size=64)\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "d8463a3a",
         "metadata": {},
         "outputs": [],
         "source": [
            "model = GoogLeNet_GAP(num_classes=2).to(device)\n",
            "criterion = torch.nn.CrossEntropyLoss()\n",
            "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
            "train_losses = []\n",
            "val_losses = []\n",
            "num_epochs = 3\n",
            "for epoch in range(num_epochs):\n",
            "    running_train_loss = 0.0\n",
            "    running_val_loss = 0.0\n",
            "    train_loader_tqdm = tqdm(train_loader, desc=\"Training\", leave=False)\n",
            "    val_loader_tqdm = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
            "    model.train()\n",
            "    for image, label in train_loader_tqdm:\n",
            "        image, label = image.to(device), label.to(device)\n",
            "        output = model(image)\n",
            "        loss = criterion(output, label)\n",
            "        optimizer.zero_grad()\n",
            "        loss.backward()\n",
            "        optimizer.step()\n",
            "        running_train_loss += loss.item()\n",
            "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
            "\n",
            "    train_losses.append(running_train_loss / len(train_loader))\n",
            "\n",
            "    model.eval()\n",
            "\n",
            "    with torch.no_grad():\n",
            "        for images, labels in val_loader_tqdm:\n",
            "            images, labels = images.to(device), labels.to(device)\n",
            "\n",
            "            outputs = model(images)\n",
            "            loss = criterion(outputs, labels)\n",
            "\n",
            "            running_val_loss += loss.item()\n",
            "            \n",
            "            val_loader_tqdm.set_postfix(loss=loss.item())\n",
            "    \n",
            "    val_losses.append(running_val_loss / len(val_loader))\n",
            "\n",
            "    print(f\"Epoch {epoch}  |  Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_losses[-1]:.4f}\")\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "82b13ea6",
         "metadata": {},
         "outputs": [],
         "source": [
            "torch.save(model.state_dict(), \"model.pth\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "28671e82",
         "metadata": {},
         "outputs": [],
         "source": [
            "# model = GoogLeNet_GAP(num_classes=2).to(device)\n",
            "# model.load_state_dict(torch.load(\"model.pth\"))\n",
            "\n",
            "# model.eval()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "005b9b44",
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "plt.figure(figsize=(10, 5))\n",
            "plt.plot(train_losses, label=\"Training Loss\", color='blue', alpha=0.7)\n",
            "plt.plot(val_losses, label=\"Val Loss\", color='orange', alpha=0.7)\n",
            "plt.xlabel(\"Iteration\")\n",
            "plt.ylabel(\"Loss\")\n",
            "plt.title(\"Training Loss Over Time\")\n",
            "plt.legend()\n",
            "plt.grid(True)\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "4be381b0",
         "metadata": {},
         "outputs": [],
         "source": [
            "testdata = val_data[random.randint(0, len(val_data) - 1)]\n",
            "while testdata[1] != 1: #pick one that has a person in it\n",
            "    testdata = val_data[random.randint(0, len(val_data) - 1)]\n",
            "testimage = Image.open(f'{data_dir}/images/val/{testdata[0]}').convert(\"RGB\")\n",
            "output = model(transforms.ToTensor()(testimage).unsqueeze(0).to(device))\n",
            "\n",
            "# Get feature maps and class weights\n",
            "feature_maps = model.feature_maps.squeeze(0)\n",
            "weights = model.classifier.weight\n",
            "\n",
            "# Choose predicted class\n",
            "pred_class = torch.argmax(output, dim=1).item()\n",
            "print(f\"pred: {pred_class}, target: {testdata[1]}\")\n",
            "class_weights = weights[pred_class]\n",
            "\n",
            "# Compute CAM\n",
            "cam = torch.einsum(\"c,chw->hw\", class_weights, feature_maps)\n",
            "cam = F.relu(cam)\n",
            "cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-5)\n",
            "overlay_cam_with_centroid(testimage, cam)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "coco-env",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.16"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
